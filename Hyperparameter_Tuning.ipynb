{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"8kTM_-8hljoL","executionInfo":{"status":"ok","timestamp":1741918975968,"user_tz":420,"elapsed":32437,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94c65930-bc1d-4742-cd1b-f80dac18b993"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras_tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (3.8.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (2.32.3)\n","Collecting kt-legacy (from keras_tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (3.12.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.14.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2025.1.31)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n","Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Installing collected packages: kt-legacy, keras_tuner\n","Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"]}],"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from xgboost import XGBRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","\n","!pip install keras_tuner\n","import keras_tuner as kt\n","\n","from sklearn import linear_model\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["# Mount to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Define Project Folder\n","FOLDERNAME = 'Colab\\ Notebooks/MATSCI176/Final\\ Project'\n","%cd drive/MyDrive/$FOLDERNAME"],"metadata":{"id":"WgngeQRElm3r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741918995903,"user_tz":420,"elapsed":19933,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"75dbce9c-d416-4491-bf22-f6a4e7b9258d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MATSCI176/Final Project\n"]}]},{"cell_type":"code","source":["# Data preprocessing for Nasa battery datasets\n","# %run convert_nasa_dataset_discharge.py"],"metadata":{"id":"komXFEP7lmyb","executionInfo":{"status":"ok","timestamp":1741918995941,"user_tz":420,"elapsed":36,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Data Pre-processing\n","\n","# Load dataset\n","file_name = \"nasa_batteries_processed/data.csv\"\n","absolute_path = os.path.abspath(file_name)  # Combine folder name and file name to create the full file path\n","df = pd.read_csv(absolute_path)\n","#df[\"load_current\"] = \"N/A\"\n","\n","#battery_id = [5, 6, 7, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56]\n","battery_id = [5, 6, 7, 18, 25, 29, 31, 34, 36, 45, 46, 47, 48, 54, 55, 56]\n","\n","value_map = {5: 2, 6: 2, 7: 2, 18: 2, 25: 4, 29: 4, 31: 1.5, 34: 4, 36: 2, 45: 1, 46: 1, 47: 1, 48: 1, 54: 2, 55: 2, 56: 2}\n","df[\"load_current\"] = df[\"battery_id\"].map(value_map)\n","\n","# Drop rows where 'SOH' has a zero value\n","df = df[df['soh'] != 0]\n","\n","# Drop rows where 'column_name' is equal to a specific value\n","#df = df[df['cycle_id'] != 0]\n","\n","# Assuming your dataframe is sorted by 'cycle_id' or any relevant column\n","df['prev_soh'] = df['soh'].shift(1)  # Get the previous SOH value\n","df['next_soh'] = df['soh'].shift(-1)  # Get the next SOH value\n","\n","# Calculate percentage differences\n","df['prev_diff'] = abs(df['soh'] - df['prev_soh'])\n","df['next_diff'] = abs(df['soh'] - df['next_soh'])\n","\n","# Add a check for the first row (compare the first row with the second)\n","df['first_row_diff'] = abs(df['soh'] - df['next_soh'])\n","df.loc[0, 'prev_diff'] = df.loc[0, 'first_row_diff']  # For the first row, set the previous difference to compare with the second\n","\n","# Filter out rows where the SOH difference exceeds 10% in the previous or next row\n","df_filtered = df[(df['prev_diff'] <= 10) & (df['next_diff'] <= 10)]\n","\n","# Drop the temporary columns used for calculation\n","df_filtered.drop(columns=['prev_soh', 'next_soh', 'prev_diff', 'next_diff', 'first_row_diff'], inplace=True)\n","\n","# Training cycles\n","n_cycles = 40"],"metadata":{"id":"XTO63GPRlmv6","executionInfo":{"status":"ok","timestamp":1741918996871,"user_tz":420,"elapsed":929,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f89bbdc3-86f3-43f9-c314-5b2afde920d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-0498139c99f3>:37: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_filtered.drop(columns=['prev_soh', 'next_soh', 'prev_diff', 'next_diff', 'first_row_diff'], inplace=True)\n"]}]},{"cell_type":"code","source":["# Data Pre-processing -> Normalization\n","\n","# Normalize SOH (optional)\n","scaler = MinMaxScaler()\n","df_filtered['SOH_scaled'] = scaler.fit_transform(df_filtered[['soh']])\n","\n","# Train-Test Split Function\n","def prepare_data(df, battery_id):\n","    battery_data = df[df['battery_id'] == battery_id].sort_values(by=\"cycle_id\")\n","    train = battery_data[battery_data[\"cycle_id\"] <= n_cycles]\n","    test = battery_data[battery_data[\"cycle_id\"] > n_cycles]\n","    return train, test\n","\n","# Apply to all batteries\n","train_list, test_list = [], []\n","for b in battery_id:\n","    train, test = prepare_data(df_filtered, b)\n","    train_list.append(train)\n","    test_list.append(test)\n","\n","train_df = pd.concat(train_list)\n","test_df = pd.concat(test_list)"],"metadata":{"id":"uK_HQJMQlmrD","executionInfo":{"status":"ok","timestamp":1741918997047,"user_tz":420,"elapsed":177,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"135e50f9-d387-4c89-9141-007dd0ff8968"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-1531a34d3b35>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_filtered['SOH_scaled'] = scaler.fit_transform(df_filtered[['soh']])\n"]}]},{"cell_type":"code","source":["# Feature Selection -> single feature\n","features = [\"cycle_id\"]  # You can add more time-based features\n","X_train, y_train = train_df[features], train_df[\"SOH_scaled\"]\n","X_test, y_test = test_df[features], test_df[\"SOH_scaled\"]"],"metadata":{"id":"bbHBl_25LpUs","executionInfo":{"status":"ok","timestamp":1741918997049,"user_tz":420,"elapsed":2,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# XGBoost Model -> calculate MAE for entire dataset\n","# Use only cycle_id as feature for training\n","\n","# Train XGBoost Model\n","xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n","xgb_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred = xgb_model.predict(X_test)\n","\n","# Evaluate Performance\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"XGBoost MAE (single feature): {mae}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Agi95ooOJZfe","executionInfo":{"status":"ok","timestamp":1741918997407,"user_tz":420,"elapsed":358,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"dca7a3ca-7883-4233-e90c-f30f8ae81c55"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost MAE (single feature): 0.10692547382669404\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for XGBoost model using single feature\n","\n","# Define parameter grid\n","param_grid = {\n","    \"n_estimators\": [100, 200, 500],\n","    \"learning_rate\": [0.01, 0.1, 0.2],\n","    \"max_depth\": [3, 5, 7],\n","    \"subsample\": [0.7, 0.8, 1.0],\n","    \"colsample_bytree\": [0.7, 0.8, 1.0]\n","}\n","\n","# Create model\n","xgb_model = XGBRegressor(random_state=42)\n","\n","# Perform Grid Search with 5-fold cross-validation\n","grid_search = GridSearchCV(\n","    estimator=xgb_model, param_grid=param_grid,\n","    cv=5, scoring='neg_mean_absolute_error',\n","    n_jobs=-1, verbose=1\n",")\n","\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Evaluate on test set\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test)\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"Optimized XGBoost MAE (single feature): {mae}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVkh3fnRe0zD","executionInfo":{"status":"ok","timestamp":1741919083343,"user_tz":420,"elapsed":85935,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"e53c985d-37dd-40c4-d715-16418d0a4fa2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n","Best Hyperparameters: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n","Optimized XGBoost MAE (single feature): 0.10624439054066982\n"]}]},{"cell_type":"code","source":["# Random Forest Model -> calculate MAE for entire dataset\n","# Use only cycle_id as feature for training\n","\n","# Train Random Forest Model\n","rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Evaluate\n","mae_rf = mean_absolute_error(y_test, y_pred_rf)\n","print(f\"Random Forest MAE (single feature): {mae_rf}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAQyXwV5J1SK","executionInfo":{"status":"ok","timestamp":1741919083647,"user_tz":420,"elapsed":306,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"27e8fb2a-d6ab-4914-e753-8e17c357584f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest MAE (single feature): 0.1070223724333034\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for Random Forest model using single feature\n","\n","# Define parameter grid\n","param_grid = {\n","    \"n_estimators\": [50, 100, 200],  # Number of trees in the forest\n","    \"max_depth\": [None, 10, 20],  # Maximum depth of the trees\n","    \"min_samples_split\": [2, 5, 10],  # Minimum samples required to split a node\n","    \"min_samples_leaf\": [1, 2, 4],  # Minimum samples required in a leaf node\n","    \"max_features\": [\"sqrt\", \"log2\"]  # Number of features to consider at each split\n","}\n","\n","# Initialize Random Forest Model\n","rf_model = RandomForestRegressor(random_state=42)\n","\n","# Perform Grid Search with 5-fold cross-validation\n","grid_search = GridSearchCV(\n","    estimator=rf_model, param_grid=param_grid,\n","    cv=5, scoring='neg_mean_absolute_error',\n","    n_jobs=-1, verbose=1\n",")\n","\n","# Fit the model\n","grid_search.fit(X_train, y_train)\n","\n","# Get best parameters\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Evaluate the best model on the test set\n","best_rf_model = grid_search.best_estimator_\n","y_pred_rf = best_rf_model.predict(X_test)\n","\n","# Calculate MAE\n","mae_rf = mean_absolute_error(y_test, y_pred_rf)\n","print(f\"Optimized Random Forest MAE (single feature): {mae_rf}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjwc-aXCP5Ho","executionInfo":{"status":"ok","timestamp":1741919227462,"user_tz":420,"elapsed":143815,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"87c67d7e-63b8-4895-d528-8748f90473e6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 162 candidates, totalling 810 fits\n","Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n","Optimized Random Forest MAE (single feature): 0.10678655404209662\n"]}]},{"cell_type":"code","source":["# Feature Selection -> multiple features\n","features = [\"ambient_temperature\", \"cutoff_voltage\", \"cycle_id\", \"load_current\"]  # You can add more time-based features\n","X_train, y_train = train_df[features], train_df[\"SOH_scaled\"]\n","X_test, y_test = test_df[features], test_df[\"SOH_scaled\"]"],"metadata":{"id":"VSO57Ld9Ks6c","executionInfo":{"status":"ok","timestamp":1741919227467,"user_tz":420,"elapsed":11,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# XGBoost Model -> calculate MAE for entire dataset\n","# Use multiple features for training\n","\n","# Train XGBoost Model\n","xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n","xgb_model.fit(X_train, y_train)\n","\n","\n","# Predict\n","y_pred = xgb_model.predict(X_test)\n","\n","# Evaluate Performance\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"XGBoost MAE (multiple feature): {mae}\")"],"metadata":{"id":"dJB1Qtmjlmoh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741919227486,"user_tz":420,"elapsed":26,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"f32bdb37-3731-4de3-88aa-da978c07e2a9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost MAE (multiple feature): 0.07291767470569481\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for XGBoost model using multiple features\n","\n","# Define parameter grid\n","param_grid = {\n","    \"n_estimators\": [100, 200, 500],  # Number of boosting rounds\n","    \"learning_rate\": [0.01, 0.1, 0.2],  # Step size shrinkage\n","    \"max_depth\": [3, 5, 7],  # Maximum depth of a tree\n","    \"subsample\": [0.7, 0.8, 1.0],  # Fraction of samples used per boosting round\n","    \"colsample_bytree\": [0.7, 0.8, 1.0],  # Fraction of features used per tree\n","    \"gamma\": [0, 0.1, 0.2],  # Minimum loss reduction to make a split\n","    \"reg_alpha\": [0, 0.1, 1],  # L1 regularization term\n","    \"reg_lambda\": [1, 2, 5]  # L2 regularization term\n","}\n","\n","# Initialize XGBoost Model\n","xgb_model = XGBRegressor(random_state=42)\n","\n","# Perform Grid Search with 5-fold cross-validation\n","grid_search = GridSearchCV(\n","    estimator=xgb_model, param_grid=param_grid,\n","    cv=5, scoring='neg_mean_absolute_error',\n","    n_jobs=-1, verbose=1\n",")\n","\n","# Fit the model\n","grid_search.fit(X_train, y_train)\n","\n","# Get best parameters\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Evaluate the best model on the test set\n","best_xgb_model = grid_search.best_estimator_\n","y_pred_xgb = best_xgb_model.predict(X_test)\n","\n","# Calculate MAE\n","mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n","print(f\"Optimized XGBoost MAE (multiple features): {mae_xgb}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAQj1WZdQ92I","executionInfo":{"status":"ok","timestamp":1741920692291,"user_tz":420,"elapsed":1464805,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"3f210481-c072-44e2-adad-419e6446a774"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 6561 candidates, totalling 32805 fits\n","Best Hyperparameters: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 5, 'subsample': 0.8}\n","Optimized XGBoost MAE (multiple features): 0.07286844942668136\n"]}]},{"cell_type":"code","source":["# Random Forest Model -> calculate MAE for entire dataset\n","# Use multiple features for training\n","\n","# Train Random Forest Model\n","rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Evaluate\n","mae_rf = mean_absolute_error(y_test, y_pred_rf)\n","print(f\"Random Forest MAE (multiple features): {mae_rf}\")"],"metadata":{"id":"03gM0w98lml7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741920692484,"user_tz":420,"elapsed":196,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"621ddba9-f5ca-4e65-8a2d-53de48d33dfd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest MAE (multiple features): 0.07452653562603848\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for Random Forest model using multiple features\n","\n","# Define parameter grid\n","param_grid = {\n","    \"n_estimators\": [100, 200, 500],  # Number of trees in the forest\n","    \"max_depth\": [None, 10, 20],  # Maximum depth of the trees\n","    \"min_samples_split\": [2, 5, 10],  # Minimum samples required to split a node\n","    \"min_samples_leaf\": [1, 2, 4],  # Minimum samples required in a leaf node\n","    \"max_features\": [\"sqrt\", \"log2\"],  # Number of features to consider at each split\n","    \"bootstrap\": [True, False]  # Whether to use bootstrapping samples\n","}\n","\n","# Initialize Random Forest Model\n","rf_model = RandomForestRegressor(random_state=42)\n","\n","# Perform Grid Search with 5-fold cross-validation\n","grid_search = GridSearchCV(\n","    estimator=rf_model, param_grid=param_grid,\n","    cv=5, scoring='neg_mean_absolute_error',\n","    n_jobs=-1, verbose=1\n",")\n","\n","# Fit the model\n","grid_search.fit(X_train, y_train)\n","\n","# Get best parameters\n","print(\"Best Hyperparameters:\", grid_search.best_params_)\n","\n","# Evaluate the best model on the test set\n","best_rf_model = grid_search.best_estimator_\n","y_pred_rf = best_rf_model.predict(X_test)\n","\n","# Calculate MAE\n","mae_rf = mean_absolute_error(y_test, y_pred_rf)\n","print(f\"Optimized Random Forest MAE: {mae_rf}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKqgUE0yRHvy","executionInfo":{"status":"ok","timestamp":1741921311514,"user_tz":420,"elapsed":619023,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"735bfbb5-927f-4098-bc31-83e5980016e7"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n","Best Hyperparameters: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 500}\n","Optimized Random Forest MAE: 0.07562066476114607\n"]}]},{"cell_type":"code","source":["# LSTM Model -> calculate MAE for entire dataset\n","# Use only battery_id as feature for training\n","\n","# Reshape Data for LSTM\n","def reshape_for_lstm(df_filtered):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        cycles = group[\"cycle_id\"].values.reshape(-1, 1)  # Use cycle_id as time-series input\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(cycles) - n_cycles):  # Use first 30 cycles as input\n","            X.append(cycles[i:i+n_cycles])\n","            y.append(soh[i+n_cycles])\n","    return np.array(X), np.array(y)\n","\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df)\n","\n","# Reshape to (samples, timesteps, features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n","\n","# Build LSTM Model\n","lstm_model = Sequential([\n","    LSTM(50, return_sequences=True, input_shape=(n_cycles, 1)),\n","    LSTM(50, return_sequences=False),\n","    Dense(25, activation=\"relu\"),\n","    Dense(1)  # Output layer\n","])\n","\n","lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n","\n","# Train Model\n","lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_lstm = lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\n","print(f\"LSTM MAE (single feature): {mae_lstm}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhRpTWIBeGZx","executionInfo":{"status":"ok","timestamp":1741921362424,"user_tz":420,"elapsed":50912,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"5bc1a226-ecfd-4f90-846a-deec562697f6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 0.6360 - val_loss: 0.2112\n","Epoch 2/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.2851 - val_loss: 0.0898\n","Epoch 3/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0921 - val_loss: 0.0318\n","Epoch 4/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714ms/step - loss: 0.0049 - val_loss: 0.0294\n","Epoch 5/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.0186 - val_loss: 0.0549\n","Epoch 6/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step - loss: 0.0692 - val_loss: 0.0746\n","Epoch 7/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.0931 - val_loss: 0.0757\n","Epoch 8/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - loss: 0.0811 - val_loss: 0.0629\n","Epoch 9/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980ms/step - loss: 0.0504 - val_loss: 0.0453\n","Epoch 10/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895ms/step - loss: 0.0205 - val_loss: 0.0301\n","Epoch 11/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988ms/step - loss: 0.0030 - val_loss: 0.0199\n","Epoch 12/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 7.6719e-04 - val_loss: 0.0155\n","Epoch 13/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903ms/step - loss: 0.0092 - val_loss: 0.0152\n","Epoch 14/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0207 - val_loss: 0.0159\n","Epoch 15/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step - loss: 0.0285 - val_loss: 0.0158\n","Epoch 16/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0295 - val_loss: 0.0148\n","Epoch 17/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0244 - val_loss: 0.0140\n","Epoch 18/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step - loss: 0.0161 - val_loss: 0.0146\n","Epoch 19/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step - loss: 0.0079 - val_loss: 0.0175\n","Epoch 20/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step - loss: 0.0021 - val_loss: 0.0228\n","Epoch 21/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717ms/step - loss: 6.7276e-06 - val_loss: 0.0297\n","Epoch 22/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - loss: 0.0013 - val_loss: 0.0366\n","Epoch 23/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step - loss: 0.0046 - val_loss: 0.0421\n","Epoch 24/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step - loss: 0.0081 - val_loss: 0.0449\n","Epoch 25/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0100 - val_loss: 0.0446\n","Epoch 26/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995ms/step - loss: 0.0098 - val_loss: 0.0415\n","Epoch 27/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - loss: 0.0078 - val_loss: 0.0367\n","Epoch 28/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 0.0049 - val_loss: 0.0312\n","Epoch 29/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709ms/step - loss: 0.0021 - val_loss: 0.0260\n","Epoch 30/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 4.1856e-04 - val_loss: 0.0217\n","Epoch 31/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715ms/step - loss: 2.1707e-05 - val_loss: 0.0186\n","Epoch 32/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779ms/step - loss: 7.1922e-04 - val_loss: 0.0166\n","Epoch 33/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765ms/step - loss: 0.0020 - val_loss: 0.0155\n","Epoch 34/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757ms/step - loss: 0.0031 - val_loss: 0.0151\n","Epoch 35/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773ms/step - loss: 0.0036 - val_loss: 0.0152\n","Epoch 36/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979ms/step - loss: 0.0035 - val_loss: 0.0158\n","Epoch 37/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step - loss: 0.0027 - val_loss: 0.0168\n","Epoch 38/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724ms/step - loss: 0.0016 - val_loss: 0.0184\n","Epoch 39/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 6.4689e-04 - val_loss: 0.0205\n","Epoch 40/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step - loss: 9.2448e-05 - val_loss: 0.0228\n","Epoch 41/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - loss: 3.3123e-05 - val_loss: 0.0251\n","Epoch 42/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - loss: 3.6595e-04 - val_loss: 0.0269\n","Epoch 43/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step - loss: 8.5652e-04 - val_loss: 0.0281\n","Epoch 44/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 0.0012 - val_loss: 0.0284\n","Epoch 45/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878ms/step - loss: 0.0014 - val_loss: 0.0279\n","Epoch 46/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0012 - val_loss: 0.0267\n","Epoch 47/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step - loss: 8.1818e-04 - val_loss: 0.0251\n","Epoch 48/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - loss: 4.0138e-04 - val_loss: 0.0233\n","Epoch 49/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 1.0143e-04 - val_loss: 0.0217\n","Epoch 50/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 3.7764e-09 - val_loss: 0.0203\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n","LSTM MAE (single feature): 0.1083058525620212\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for LSTM model using single feature\n","\n","# Set random seed for reproducibility\n","seed = 99\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","random.seed(seed)\n","\n","# Ensure TensorFlow deterministic behavior (use if running on GPU)\n","tf.config.experimental.enable_op_determinism()\n","\n","# Hyperparameters\n","batch_size = 16\n","epochs = 50\n","\n","# Standardize cycle_id for stability\n","scaler = StandardScaler()\n","\n","# Function to reshape data for LSTM\n","def reshape_for_lstm(df_filtered, n_cycles=40):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        cycles = group[\"cycle_id\"].values.reshape(-1, 1)  # Use cycle_id as time-series input\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(cycles) - n_cycles):  # Use first 30 cycles as input\n","            X.append(cycles[i:i + n_cycles])\n","            y.append(soh[i + n_cycles])\n","    return np.array(X), np.array(y)\n","\n","# Prepare data\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df)\n","\n","# Reshape for LSTM (samples, timesteps, features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n","\n","# Define model builder function\n","def build_lstm_model(hp):\n","    model = Sequential()\n","    model.add(LSTM(\n","        units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n","        return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)\n","    ))\n","    model.add(LSTM(\n","        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n","        return_sequences=False\n","    ))\n","    model.add(Dense(hp.Int('dense_units', min_value=16, max_value=64, step=16), activation=\"relu\"))\n","    model.add(Dense(1))  # Output layer\n","\n","    model.compile(\n","        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n","        loss=\"mse\"\n","    )\n","    return model\n","\n","# Initialize tuner\n","tuner = kt.BayesianOptimization(\n","    build_lstm_model,\n","    objective=\"val_loss\",\n","    max_trials=10,  # Number of different hyperparameter combinations to try\n","    directory=\"lstm_tuning\",\n","    project_name=\"battery_lstm\"\n",")\n","\n","# Run hyperparameter search\n","tuner.search(X_train_lstm, y_train_lstm, epochs=30, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Get the best model\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","print(f\"Best Hyperparameters: {best_hps.values}\")\n","\n","# Train best model\n","best_lstm_model = tuner.hypermodel.build(best_hps)\n","best_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_lstm = best_lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\n","print(f\"Optimized LSTM MAE (single feature): {mae_lstm}\")\n","\n","# Get the best hyperparameters from the tuning process\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","# Print the best hyperparameter values\n","print(\"Best Hyperparameters:\")\n","for param, value in best_hps.values.items():\n","    print(f\"{param}: {value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PNIjhR2ggNlC","executionInfo":{"status":"ok","timestamp":1741921424775,"user_tz":420,"elapsed":62350,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"c508d728-1503-437b-b9a4-06821705e4ba"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Reloading Tuner from lstm_tuning/battery_lstm/tuner0.json\n","Best Hyperparameters: {'units_1': 128, 'units_2': 64, 'dense_units': 32, 'learning_rate': 0.0001}\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 0.3149 - val_loss: 0.1952\n","Epoch 2/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769ms/step - loss: 0.2282 - val_loss: 0.1527\n","Epoch 3/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.1553 - val_loss: 0.1163\n","Epoch 4/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0967 - val_loss: 0.0860\n","Epoch 5/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0525 - val_loss: 0.0617\n","Epoch 6/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0226 - val_loss: 0.0427\n","Epoch 7/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0057 - val_loss: 0.0290\n","Epoch 8/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 5.5406e-05 - val_loss: 0.0202\n","Epoch 9/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632ms/step - loss: 0.0028 - val_loss: 0.0154\n","Epoch 10/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735ms/step - loss: 0.0106 - val_loss: 0.0135\n","Epoch 11/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761ms/step - loss: 0.0198 - val_loss: 0.0130\n","Epoch 12/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742ms/step - loss: 0.0272 - val_loss: 0.0130\n","Epoch 13/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step - loss: 0.0311 - val_loss: 0.0130\n","Epoch 14/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744ms/step - loss: 0.0313 - val_loss: 0.0130\n","Epoch 15/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0283 - val_loss: 0.0132\n","Epoch 16/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0231 - val_loss: 0.0140\n","Epoch 17/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0169 - val_loss: 0.0156\n","Epoch 18/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803ms/step - loss: 0.0108 - val_loss: 0.0182\n","Epoch 19/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0055 - val_loss: 0.0217\n","Epoch 20/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0018 - val_loss: 0.0257\n","Epoch 21/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step - loss: 1.5560e-04 - val_loss: 0.0301\n","Epoch 22/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 2.4887e-04 - val_loss: 0.0344\n","Epoch 23/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step - loss: 0.0016 - val_loss: 0.0382\n","Epoch 24/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0036 - val_loss: 0.0410\n","Epoch 25/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0056 - val_loss: 0.0427\n","Epoch 26/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step - loss: 0.0069 - val_loss: 0.0431\n","Epoch 27/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743ms/step - loss: 0.0074 - val_loss: 0.0423\n","Epoch 28/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step - loss: 0.0070 - val_loss: 0.0404\n","Epoch 29/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0059 - val_loss: 0.0379\n","Epoch 30/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0043 - val_loss: 0.0349\n","Epoch 31/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0028 - val_loss: 0.0318\n","Epoch 32/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0014 - val_loss: 0.0288\n","Epoch 33/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735ms/step - loss: 4.6200e-04 - val_loss: 0.0260\n","Epoch 34/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 3.5020e-05 - val_loss: 0.0237\n","Epoch 35/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736ms/step - loss: 7.2711e-05 - val_loss: 0.0218\n","Epoch 36/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 4.4578e-04 - val_loss: 0.0204\n","Epoch 37/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 9.7858e-04 - val_loss: 0.0194\n","Epoch 38/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step - loss: 0.0015 - val_loss: 0.0188\n","Epoch 39/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735ms/step - loss: 0.0019 - val_loss: 0.0186\n","Epoch 40/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0020 - val_loss: 0.0187\n","Epoch 41/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0019 - val_loss: 0.0191\n","Epoch 42/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743ms/step - loss: 0.0015 - val_loss: 0.0198\n","Epoch 43/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736ms/step - loss: 0.0011 - val_loss: 0.0207\n","Epoch 44/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step - loss: 6.8482e-04 - val_loss: 0.0218\n","Epoch 45/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step - loss: 3.1950e-04 - val_loss: 0.0230\n","Epoch 46/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - loss: 8.5016e-05 - val_loss: 0.0242\n","Epoch 47/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step - loss: 5.9405e-07 - val_loss: 0.0254\n","Epoch 48/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733ms/step - loss: 4.8418e-05 - val_loss: 0.0264\n","Epoch 49/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.8315e-04 - val_loss: 0.0272\n","Epoch 50/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 3.4683e-04 - val_loss: 0.0278\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n","Optimized LSTM MAE (single feature): 0.14361753510319328\n","Best Hyperparameters:\n","units_1: 128\n","units_2: 64\n","dense_units: 32\n","learning_rate: 0.0001\n"]}]},{"cell_type":"code","source":["# LSTM Model -> calculate MAE for entire dataset\n","# Use multiple features for training\n","\n","# Features to use\n","features = [\"ambient_temperature\", \"cutoff_voltage\", \"cycle_id\", \"load_current\"]\n","\n","# Reshape Data for LSTM\n","def reshape_for_lstm(df_filtered):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        feature_values = group[features].values  # Extract multiple features\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(feature_values) - n_cycles):  # Use first 30 cycles as input\n","            X.append(feature_values[i:i+n_cycles])\n","            y.append(soh[i+n_cycles])  # Predict SOH at cycle i+30\n","    return np.array(X), np.array(y)\n","\n","# Prepare LSTM Training & Testing Data\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df)\n","\n","# Reshape to (samples, timesteps, features)\n","num_features = len(features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], num_features)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], num_features)\n","\n","# Build LSTM Model\n","lstm_model = Sequential([\n","    LSTM(50, return_sequences=True, input_shape=(n_cycles, num_features)),  # Adjust input shape\n","    LSTM(50, return_sequences=False),\n","    Dense(25, activation=\"relu\"),\n","    Dense(1)  # Output layer\n","])\n","\n","lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n","\n","# Train Model\n","lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_lstm = lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\n","print(f\"LSTM MAE (multiple features): {mae_lstm:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V69pWnAZkrTe","executionInfo":{"status":"ok","timestamp":1741921473397,"user_tz":420,"elapsed":48618,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"ab08aede-8145-4a7a-cd2f-df349a93eb49"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.5834 - val_loss: 0.4568\n","Epoch 2/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740ms/step - loss: 0.4619 - val_loss: 0.3533\n","Epoch 3/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - loss: 0.3486 - val_loss: 0.2652\n","Epoch 4/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - loss: 0.2364 - val_loss: 0.1831\n","Epoch 5/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895ms/step - loss: 0.1397 - val_loss: 0.1169\n","Epoch 6/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0669 - val_loss: 0.0684\n","Epoch 7/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994ms/step - loss: 0.0203 - val_loss: 0.0361\n","Epoch 8/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step - loss: 0.0010 - val_loss: 0.0192\n","Epoch 9/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718ms/step - loss: 0.0052 - val_loss: 0.0156\n","Epoch 10/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0232 - val_loss: 0.0185\n","Epoch 11/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0375 - val_loss: 0.0211\n","Epoch 12/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0393 - val_loss: 0.0216\n","Epoch 13/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0329 - val_loss: 0.0197\n","Epoch 14/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780ms/step - loss: 0.0217 - val_loss: 0.0165\n","Epoch 15/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - loss: 0.0107 - val_loss: 0.0130\n","Epoch 16/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0031 - val_loss: 0.0103\n","Epoch 17/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - loss: 7.8418e-05 - val_loss: 0.0086\n","Epoch 18/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892ms/step - loss: 0.0011 - val_loss: 0.0079\n","Epoch 19/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715ms/step - loss: 0.0045 - val_loss: 0.0076\n","Epoch 20/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0082 - val_loss: 0.0076\n","Epoch 21/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - loss: 0.0108 - val_loss: 0.0075\n","Epoch 22/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step - loss: 0.0115 - val_loss: 0.0075\n","Epoch 23/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973ms/step - loss: 0.0103 - val_loss: 0.0075\n","Epoch 24/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719ms/step - loss: 0.0079 - val_loss: 0.0079\n","Epoch 25/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0050 - val_loss: 0.0088\n","Epoch 26/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780ms/step - loss: 0.0025 - val_loss: 0.0102\n","Epoch 27/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step - loss: 7.3691e-04 - val_loss: 0.0121\n","Epoch 28/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770ms/step - loss: 2.1287e-05 - val_loss: 0.0143\n","Epoch 29/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 2.5998e-04 - val_loss: 0.0166\n","Epoch 30/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - loss: 0.0011 - val_loss: 0.0185\n","Epoch 31/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889ms/step - loss: 0.0022 - val_loss: 0.0199\n","Epoch 32/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - loss: 0.0030 - val_loss: 0.0206\n","Epoch 33/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step - loss: 0.0034 - val_loss: 0.0204\n","Epoch 34/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - loss: 0.0032 - val_loss: 0.0196\n","Epoch 35/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step - loss: 0.0025 - val_loss: 0.0184\n","Epoch 36/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880ms/step - loss: 0.0016 - val_loss: 0.0168\n","Epoch 37/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 8.1761e-04 - val_loss: 0.0153\n","Epoch 38/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step - loss: 2.4599e-04 - val_loss: 0.0138\n","Epoch 39/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726ms/step - loss: 7.9078e-06 - val_loss: 0.0127\n","Epoch 40/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998ms/step - loss: 8.1359e-05 - val_loss: 0.0117\n","Epoch 41/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628ms/step - loss: 3.6075e-04 - val_loss: 0.0111\n","Epoch 42/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - loss: 7.0295e-04 - val_loss: 0.0108\n","Epoch 43/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715ms/step - loss: 9.7524e-04 - val_loss: 0.0106\n","Epoch 44/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step - loss: 0.0011 - val_loss: 0.0108\n","Epoch 45/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.0010 - val_loss: 0.0111\n","Epoch 46/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812ms/step - loss: 8.1798e-04 - val_loss: 0.0116\n","Epoch 47/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step - loss: 5.3652e-04 - val_loss: 0.0122\n","Epoch 48/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - loss: 2.6685e-04 - val_loss: 0.0130\n","Epoch 49/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 7.7102e-05 - val_loss: 0.0139\n","Epoch 50/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step - loss: 1.3858e-06 - val_loss: 0.0147\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n","LSTM MAE (multiple features): 0.1021\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for LSTM model using multiple features\n","\n","# Set random seed for reproducibility\n","seed = 99\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","random.seed(seed)\n","\n","# Ensure TensorFlow deterministic behavior (use if running on GPU)\n","tf.config.experimental.enable_op_determinism()\n","\n","# Hyperparameters\n","batch_size = 16\n","epochs = 50\n","\n","# Standardize cycle_id for stability\n","scaler = StandardScaler()\n","\n","# Features to use\n","features = [\"ambient_temperature\", \"cutoff_voltage\", \"cycle_id\", \"load_current\"]\n","\n","# Function to reshape data for LSTM\n","def reshape_for_lstm(df_filtered, n_cycles=30):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        feature_values = group[features].values  # Extract multiple features\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(feature_values) - n_cycles):  # Use first 30 cycles as input\n","            X.append(feature_values[i:i + n_cycles])\n","            y.append(soh[i + n_cycles])  # Predict SOH at cycle i+30\n","    return np.array(X), np.array(y)\n","\n","# Prepare LSTM Training & Testing Data\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df)\n","\n","# Reshape to (samples, timesteps, features)\n","num_features = len(features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], num_features)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], num_features)\n","\n","# Define model builder function for tuning\n","def build_lstm_model(hp):\n","    model = Sequential()\n","\n","    # First LSTM layer\n","    model.add(LSTM(\n","        units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n","        return_sequences=True,\n","        input_shape=(X_train_lstm.shape[1], num_features)\n","    ))\n","\n","    # Second LSTM layer\n","    model.add(LSTM(\n","        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n","        return_sequences=False\n","    ))\n","\n","    # Dropout layer for regularization\n","    model.add(Dropout(hp.Choice('dropout', [0.0, 0.2, 0.4])))\n","\n","    # Dense layer\n","    model.add(Dense(hp.Int('dense_units', min_value=16, max_value=64, step=16), activation=\"relu\"))\n","\n","    # Output layer\n","    model.add(Dense(1))\n","\n","    # Compile model\n","    model.compile(\n","        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n","        loss=\"mse\"\n","    )\n","\n","    return model\n","\n","# Initialize tuner\n","tuner = kt.BayesianOptimization(\n","    build_lstm_model,\n","    objective=\"val_loss\",\n","    max_trials=10,  # Number of different hyperparameter combinations to try\n","    directory=\"lstm_tuning\",\n","    project_name=\"battery_lstm_multifeature\"\n",")\n","\n","# Run hyperparameter search\n","tuner.search(X_train_lstm, y_train_lstm, epochs=30, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Get the best model\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","print(f\"Best Hyperparameters: {best_hps.values}\")\n","\n","# Train the best model\n","best_lstm_model = tuner.hypermodel.build(best_hps)\n","best_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_lstm = best_lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\n","print(f\"Optimized LSTM MAE (multiple features): {mae_lstm:.4f}\")\n","\n","# Print the best hyperparameter values\n","print(\"Best Hyperparameters:\")\n","for param, value in best_hps.values.items():\n","    print(f\"{param}: {value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aARdrRivgfo4","executionInfo":{"status":"ok","timestamp":1741921539260,"user_tz":420,"elapsed":65859,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"f2810da0-1ae2-4e1f-c670-bac2f7643a15"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Reloading Tuner from lstm_tuning/battery_lstm_multifeature/tuner0.json\n","Best Hyperparameters: {'units_1': 96, 'units_2': 64, 'dropout': 0.2, 'dense_units': 48, 'learning_rate': 0.0005}\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 0.2280 - val_loss: 0.0101\n","Epoch 2/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0394 - val_loss: 0.0838\n","Epoch 3/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0229 - val_loss: 0.0307\n","Epoch 4/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0223 - val_loss: 0.0323\n","Epoch 5/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 0.0196 - val_loss: 0.0439\n","Epoch 6/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0126 - val_loss: 0.0348\n","Epoch 7/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0152 - val_loss: 0.0371\n","Epoch 8/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0174 - val_loss: 0.0389\n","Epoch 9/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0160 - val_loss: 0.0360\n","Epoch 10/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0133 - val_loss: 0.0315\n","Epoch 11/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0143 - val_loss: 0.0315\n","Epoch 12/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0109 - val_loss: 0.0324\n","Epoch 13/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0135 - val_loss: 0.0248\n","Epoch 14/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0132 - val_loss: 0.0265\n","Epoch 15/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0139 - val_loss: 0.0223\n","Epoch 16/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0121 - val_loss: 0.0300\n","Epoch 17/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0096 - val_loss: 0.0295\n","Epoch 18/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0118 - val_loss: 0.0263\n","Epoch 19/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0126 - val_loss: 0.0279\n","Epoch 20/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0115 - val_loss: 0.0180\n","Epoch 21/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0101 - val_loss: 0.0202\n","Epoch 22/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0108 - val_loss: 0.0186\n","Epoch 23/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0100 - val_loss: 0.0242\n","Epoch 24/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0113 - val_loss: 0.0242\n","Epoch 25/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0098 - val_loss: 0.0311\n","Epoch 26/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0074 - val_loss: 0.0307\n","Epoch 27/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0102 - val_loss: 0.0238\n","Epoch 28/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0084 - val_loss: 0.0232\n","Epoch 29/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0093 - val_loss: 0.0140\n","Epoch 30/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0089 - val_loss: 0.0195\n","Epoch 31/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0089 - val_loss: 0.0267\n","Epoch 32/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0090 - val_loss: 0.0256\n","Epoch 33/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0104 - val_loss: 0.0283\n","Epoch 34/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0076 - val_loss: 0.0252\n","Epoch 35/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0094 - val_loss: 0.0313\n","Epoch 36/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0067 - val_loss: 0.0273\n","Epoch 37/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0061 - val_loss: 0.0294\n","Epoch 38/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0075 - val_loss: 0.0299\n","Epoch 39/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0086 - val_loss: 0.0305\n","Epoch 40/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0072 - val_loss: 0.0278\n","Epoch 41/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0077 - val_loss: 0.0234\n","Epoch 42/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0074 - val_loss: 0.0203\n","Epoch 43/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0080 - val_loss: 0.0223\n","Epoch 44/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0087 - val_loss: 0.0358\n","Epoch 45/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0084 - val_loss: 0.0369\n","Epoch 46/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0062 - val_loss: 0.0390\n","Epoch 47/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0055 - val_loss: 0.0472\n","Epoch 48/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0065 - val_loss: 0.0397\n","Epoch 49/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0042 - val_loss: 0.0415\n","Epoch 50/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0059 - val_loss: 0.0434\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n","Optimized LSTM MAE (multiple features): 0.1907\n","Best Hyperparameters:\n","units_1: 96\n","units_2: 64\n","dropout: 0.2\n","dense_units: 48\n","learning_rate: 0.0005\n"]}]},{"cell_type":"code","source":["# Bi-directional LSTM -> calculate MAE for entire dataset\n","# Use only battery_id as feature for training\n","\n","from tensorflow.keras.layers import Bidirectional\n","\n","# Reshape Data for LSTM\n","def reshape_for_lstm(df_filtered, n_cycles):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        cycles = group[\"cycle_id\"].values.reshape(-1, 1)  # Use cycle_id as time-series input\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(cycles) - n_cycles):  # Use first 30 cycles as input\n","            X.append(cycles[i:i+n_cycles])\n","            y.append(soh[i+n_cycles])\n","    return np.array(X), np.array(y)\n","\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df, 30)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df, 30)\n","\n","# Reshape to (samples, timesteps, features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n","\n","# Build Bi-LSTM Model\n","bi_lstm_model = Sequential([\n","    Bidirectional(LSTM(50, return_sequences=True), input_shape=(30, 1)),  # Bidirectional LSTM layer\n","    Bidirectional(LSTM(50, return_sequences=False)),  # Another Bidirectional LSTM layer\n","    Dense(25, activation=\"relu\"),\n","    Dense(1)  # Output layer\n","])\n","\n","bi_lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n","\n","# Train Model\n","bi_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_bi_lstm = bi_lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_bi_lstm = mean_absolute_error(y_test_lstm, y_pred_bi_lstm)\n","print(f\"Bi-LSTM MAE (single feature): {mae_bi_lstm}\")"],"metadata":{"id":"nAUXK7cmeGtg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741921617947,"user_tz":420,"elapsed":78686,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"e28ab75a-1b96-4358-855d-162e88999a18"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - loss: 0.4710 - val_loss: 0.0374\n","Epoch 2/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0615 - val_loss: 0.0960\n","Epoch 3/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0425 - val_loss: 0.0472\n","Epoch 4/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - loss: 0.0368 - val_loss: 0.0683\n","Epoch 5/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0364 - val_loss: 0.0532\n","Epoch 6/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0359 - val_loss: 0.0606\n","Epoch 7/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0358 - val_loss: 0.0554\n","Epoch 8/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0358 - val_loss: 0.0572\n","Epoch 9/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0357 - val_loss: 0.0554\n","Epoch 10/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0358 - val_loss: 0.0548\n","Epoch 11/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0357 - val_loss: 0.0540\n","Epoch 12/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0357 - val_loss: 0.0527\n","Epoch 13/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0356 - val_loss: 0.0520\n","Epoch 14/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0357 - val_loss: 0.0505\n","Epoch 15/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0357 - val_loss: 0.0496\n","Epoch 16/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0356 - val_loss: 0.0484\n","Epoch 17/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0356 - val_loss: 0.0473\n","Epoch 18/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0356 - val_loss: 0.0463\n","Epoch 19/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0356 - val_loss: 0.0453\n","Epoch 20/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0356 - val_loss: 0.0444\n","Epoch 21/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0356 - val_loss: 0.0434\n","Epoch 22/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0356 - val_loss: 0.0426\n","Epoch 23/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0356 - val_loss: 0.0417\n","Epoch 24/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0356 - val_loss: 0.0409\n","Epoch 25/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - loss: 0.0356 - val_loss: 0.0402\n","Epoch 26/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0356 - val_loss: 0.0396\n","Epoch 27/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0356 - val_loss: 0.0389\n","Epoch 28/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0355 - val_loss: 0.0382\n","Epoch 29/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0355 - val_loss: 0.0376\n","Epoch 30/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0355 - val_loss: 0.0371\n","Epoch 31/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0355 - val_loss: 0.0366\n","Epoch 32/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0355 - val_loss: 0.0362\n","Epoch 33/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0355 - val_loss: 0.0357\n","Epoch 34/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0355 - val_loss: 0.0353\n","Epoch 35/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0355 - val_loss: 0.0348\n","Epoch 36/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0355 - val_loss: 0.0343\n","Epoch 37/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0354 - val_loss: 0.0338\n","Epoch 38/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0354 - val_loss: 0.0334\n","Epoch 39/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0354 - val_loss: 0.0329\n","Epoch 40/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0354 - val_loss: 0.0326\n","Epoch 41/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0354 - val_loss: 0.0322\n","Epoch 42/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0354 - val_loss: 0.0319\n","Epoch 43/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0354 - val_loss: 0.0316\n","Epoch 44/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0354 - val_loss: 0.0312\n","Epoch 45/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0354 - val_loss: 0.0308\n","Epoch 46/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0354 - val_loss: 0.0305\n","Epoch 47/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0353 - val_loss: 0.0301\n","Epoch 48/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0353 - val_loss: 0.0298\n","Epoch 49/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0353 - val_loss: 0.0297\n","Epoch 50/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0353 - val_loss: 0.0296\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step\n","Bi-LSTM MAE (single feature): 0.15794883306113483\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for Bi-LSTM model using single feature\n","\n","# Function to reshape data for LSTM\n","def reshape_for_lstm(df_filtered, n_cycles=30):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        cycles = group[\"cycle_id\"].values.reshape(-1, 1)  # Use cycle_id as time-series input\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(cycles) - n_cycles):  # Use first 30 cycles as input\n","            X.append(cycles[i:i + n_cycles])\n","            y.append(soh[i + n_cycles])\n","    return np.array(X), np.array(y)\n","\n","# Prepare LSTM Training & Testing Data\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df)\n","\n","# Reshape to (samples, timesteps, features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n","\n","# Define model builder function for tuning\n","def build_bi_lstm_model(hp):\n","    model = Sequential()\n","\n","    # First Bi-LSTM layer\n","    model.add(Bidirectional(LSTM(\n","        units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n","        return_sequences=True\n","    ), input_shape=(X_train_lstm.shape[1], 1)))\n","\n","    # Second Bi-LSTM layer\n","    model.add(Bidirectional(LSTM(\n","        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n","        return_sequences=False\n","    )))\n","\n","    # Dropout layer for regularization\n","    model.add(Dropout(hp.Choice('dropout', [0.0, 0.2, 0.4])))\n","\n","    # Dense layer\n","    model.add(Dense(hp.Int('dense_units', min_value=16, max_value=64, step=16), activation=\"relu\"))\n","\n","    # Output layer\n","    model.add(Dense(1))\n","\n","    # Compile model\n","    model.compile(\n","        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n","        loss=\"mse\"\n","    )\n","\n","    return model\n","\n","# Initialize tuner\n","tuner = kt.BayesianOptimization(\n","    build_bi_lstm_model,\n","    objective=\"val_loss\",\n","    max_trials=10,  # Number of different hyperparameter combinations to try\n","    directory=\"bi_lstm_tuning\",\n","    project_name=\"battery_bi_lstm\"\n",")\n","\n","# Run hyperparameter search\n","tuner.search(X_train_lstm, y_train_lstm, epochs=30, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Get the best model\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","print(f\"Best Hyperparameters: {best_hps.values}\")\n","\n","# Train the best model\n","best_bi_lstm_model = tuner.hypermodel.build(best_hps)\n","best_bi_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_bi_lstm = best_bi_lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_bi_lstm = mean_absolute_error(y_test_lstm, y_pred_bi_lstm)\n","print(f\"Optimized Bi-LSTM MAE (single feature): {mae_bi_lstm:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5voQVhZNgm0P","executionInfo":{"status":"ok","timestamp":1741921745489,"user_tz":420,"elapsed":127538,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"43303b80-dafb-4a9b-c088-9a0c48aa061e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Reloading Tuner from bi_lstm_tuning/battery_bi_lstm/tuner0.json\n","Best Hyperparameters: {'units_1': 64, 'units_2': 128, 'dropout': 0.2, 'dense_units': 64, 'learning_rate': 0.001}\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 423ms/step - loss: 0.4513 - val_loss: 0.0375\n","Epoch 2/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 235ms/step - loss: 0.0484 - val_loss: 0.0482\n","Epoch 3/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0529 - val_loss: 0.0137\n","Epoch 4/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - loss: 0.0420 - val_loss: 0.0234\n","Epoch 5/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0380 - val_loss: 0.0261\n","Epoch 6/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - loss: 0.0463 - val_loss: 0.0176\n","Epoch 7/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - loss: 0.0411 - val_loss: 0.0358\n","Epoch 8/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0368 - val_loss: 0.0301\n","Epoch 9/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0462 - val_loss: 0.0181\n","Epoch 10/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 0.0408 - val_loss: 0.0230\n","Epoch 11/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - loss: 0.0383 - val_loss: 0.0208\n","Epoch 12/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0459 - val_loss: 0.0199\n","Epoch 13/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 268ms/step - loss: 0.0406 - val_loss: 0.0221\n","Epoch 14/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0388 - val_loss: 0.0267\n","Epoch 15/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.0427 - val_loss: 0.0247\n","Epoch 16/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 0.0427 - val_loss: 0.0258\n","Epoch 17/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 234ms/step - loss: 0.0403 - val_loss: 0.0216\n","Epoch 18/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - loss: 0.0393 - val_loss: 0.0258\n","Epoch 19/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 297ms/step - loss: 0.0357 - val_loss: 0.0252\n","Epoch 20/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0395 - val_loss: 0.0199\n","Epoch 21/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0340 - val_loss: 0.0293\n","Epoch 22/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0388 - val_loss: 0.0223\n","Epoch 23/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 0.0424 - val_loss: 0.0213\n","Epoch 24/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - loss: 0.0371 - val_loss: 0.0225\n","Epoch 25/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0380 - val_loss: 0.0219\n","Epoch 26/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 259ms/step - loss: 0.0397 - val_loss: 0.0271\n","Epoch 27/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - loss: 0.0414 - val_loss: 0.0159\n","Epoch 28/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0433 - val_loss: 0.0220\n","Epoch 29/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - loss: 0.0379 - val_loss: 0.0209\n","Epoch 30/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0386 - val_loss: 0.0226\n","Epoch 31/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - loss: 0.0376 - val_loss: 0.0236\n","Epoch 32/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step - loss: 0.0417 - val_loss: 0.0179\n","Epoch 33/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - loss: 0.0352 - val_loss: 0.0163\n","Epoch 34/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0366 - val_loss: 0.0243\n","Epoch 35/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - loss: 0.0405 - val_loss: 0.0208\n","Epoch 36/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0428 - val_loss: 0.0152\n","Epoch 37/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0365 - val_loss: 0.0234\n","Epoch 38/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0365 - val_loss: 0.0221\n","Epoch 39/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - loss: 0.0363 - val_loss: 0.0235\n","Epoch 40/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0336 - val_loss: 0.0241\n","Epoch 41/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - loss: 0.0393 - val_loss: 0.0190\n","Epoch 42/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0390 - val_loss: 0.0215\n","Epoch 43/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0387 - val_loss: 0.0212\n","Epoch 44/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0357 - val_loss: 0.0220\n","Epoch 45/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 293ms/step - loss: 0.0373 - val_loss: 0.0252\n","Epoch 46/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0354 - val_loss: 0.0195\n","Epoch 47/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0382 - val_loss: 0.0237\n","Epoch 48/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - loss: 0.0371 - val_loss: 0.0206\n","Epoch 49/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0383 - val_loss: 0.0215\n","Epoch 50/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 295ms/step - loss: 0.0358 - val_loss: 0.0220\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step\n","Optimized Bi-LSTM MAE (single feature): 0.1328\n"]}]},{"cell_type":"code","source":["# Bi-directional LSTM -> calculate MAE for entire dataset\n","# Use multiple features for training\n","\n","# Features to use\n","features = [\"ambient_temperature\", \"cutoff_voltage\", \"cycle_id\", \"load_current\"]\n","\n","# Reshape Data for Bi-LSTM\n","def reshape_for_lstm(df_filtered, n_cycles):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        feature_values = group[features].values  # Extract multiple features\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(feature_values) - n_cycles):  # Use first 30 cycles as input\n","            X.append(feature_values[i:i+n_cycles])\n","            y.append(soh[i+n_cycles])  # Predict SOH at cycle i+30\n","    return np.array(X), np.array(y)\n","\n","# Prepare Bi-LSTM Training & Testing Data\n","n_cycles = 30  # Define the number of cycles used for training\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df, n_cycles)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df, n_cycles)\n","\n","# Reshape to (samples, timesteps, features)\n","num_features = len(features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], num_features)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], num_features)\n","\n","# Build Bi-LSTM Model\n","bi_lstm_model = Sequential([\n","    Bidirectional(LSTM(50, return_sequences=True), input_shape=(n_cycles, num_features)),  # Bidirectional LSTM layer\n","    Bidirectional(LSTM(50, return_sequences=False)),  # Another Bidirectional LSTM layer\n","    Dense(25, activation=\"relu\"),\n","    Dense(1)  # Output layer\n","])\n","\n","bi_lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n","\n","# Train Model\n","bi_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_bi_lstm = bi_lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_bi_lstm = mean_absolute_error(y_test_lstm, y_pred_bi_lstm)\n","print(f\"Bi-LSTM MAE (multiple features): {mae_bi_lstm:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qoxsxv_7fIul","executionInfo":{"status":"ok","timestamp":1741921819912,"user_tz":420,"elapsed":74419,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"1ea3d7a8-8527-4953-97de-80ad43c60164"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.3779 - val_loss: 0.0198\n","Epoch 2/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - loss: 0.0292 - val_loss: 0.0771\n","Epoch 3/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0117 - val_loss: 0.0167\n","Epoch 4/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0104 - val_loss: 0.0387\n","Epoch 5/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0066 - val_loss: 0.0201\n","Epoch 6/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0083 - val_loss: 0.0378\n","Epoch 7/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0059 - val_loss: 0.0274\n","Epoch 8/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0069 - val_loss: 0.0371\n","Epoch 9/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0055 - val_loss: 0.0333\n","Epoch 10/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0062 - val_loss: 0.0387\n","Epoch 11/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0056 - val_loss: 0.0374\n","Epoch 12/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0056 - val_loss: 0.0400\n","Epoch 13/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0055 - val_loss: 0.0411\n","Epoch 14/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0054 - val_loss: 0.0417\n","Epoch 15/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0053 - val_loss: 0.0433\n","Epoch 16/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0052 - val_loss: 0.0437\n","Epoch 17/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0051 - val_loss: 0.0453\n","Epoch 18/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0050 - val_loss: 0.0458\n","Epoch 19/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0049 - val_loss: 0.0469\n","Epoch 20/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0048 - val_loss: 0.0479\n","Epoch 21/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0047 - val_loss: 0.0486\n","Epoch 22/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0046 - val_loss: 0.0480\n","Epoch 23/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0045 - val_loss: 0.0466\n","Epoch 24/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0044 - val_loss: 0.0479\n","Epoch 25/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0042 - val_loss: 0.0466\n","Epoch 26/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0041 - val_loss: 0.0473\n","Epoch 27/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0036 - val_loss: 0.0454\n","Epoch 28/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0035 - val_loss: 0.0463\n","Epoch 29/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0032 - val_loss: 0.0367\n","Epoch 30/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0030 - val_loss: 0.0296\n","Epoch 31/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0031 - val_loss: 0.0383\n","Epoch 32/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0037 - val_loss: 0.0327\n","Epoch 33/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 251ms/step - loss: 0.0023 - val_loss: 0.0347\n","Epoch 34/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 0.0038 - val_loss: 0.0339\n","Epoch 35/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0038 - val_loss: 0.0270\n","Epoch 36/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0028 - val_loss: 0.0329\n","Epoch 37/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0033 - val_loss: 0.0315\n","Epoch 38/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0026 - val_loss: 0.0368\n","Epoch 39/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0021 - val_loss: 0.0376\n","Epoch 40/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0023 - val_loss: 0.0341\n","Epoch 41/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0027 - val_loss: 0.0295\n","Epoch 42/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0041 - val_loss: 0.0401\n","Epoch 43/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0037 - val_loss: 0.0312\n","Epoch 44/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - loss: 0.0044 - val_loss: 0.0376\n","Epoch 45/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0029 - val_loss: 0.0330\n","Epoch 46/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0031 - val_loss: 0.0333\n","Epoch 47/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0022 - val_loss: 0.0346\n","Epoch 48/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0026 - val_loss: 0.0373\n","Epoch 49/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0032 - val_loss: 0.0402\n","Epoch 50/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0043 - val_loss: 0.0367\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step\n","Bi-LSTM MAE (multiple features): 0.1743\n"]}]},{"cell_type":"code","source":["# Hyperparameter tuning for Bi-LSTM model using multiple features\n","\n","# Features to use\n","features = [\"ambient_temperature\", \"cutoff_voltage\", \"cycle_id\", \"load_current\"]\n","\n","# Reshape Data for Bi-LSTM\n","def reshape_for_lstm(df_filtered, n_cycles=30):\n","    X, y = [], []\n","    grouped = df_filtered.groupby(\"battery_id\")\n","    for _, group in grouped:\n","        feature_values = group[features].values  # Extract multiple features\n","        soh = group[\"SOH_scaled\"].values\n","        for i in range(len(feature_values) - n_cycles):  # Use first 30 cycles as input\n","            X.append(feature_values[i:i + n_cycles])\n","            y.append(soh[i + n_cycles])  # Predict SOH at cycle i+30\n","    return np.array(X), np.array(y)\n","\n","# Prepare Bi-LSTM Training & Testing Data\n","n_cycles = 30  # Define the number of cycles used for training\n","X_train_lstm, y_train_lstm = reshape_for_lstm(train_df, n_cycles)\n","X_test_lstm, y_test_lstm = reshape_for_lstm(test_df, n_cycles)\n","\n","# Reshape to (samples, timesteps, features)\n","num_features = len(features)\n","X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], num_features)\n","X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], num_features)\n","\n","# Define model builder function for tuning\n","def build_bi_lstm_model(hp):\n","    model = Sequential()\n","\n","    # First Bi-LSTM layer\n","    model.add(Bidirectional(LSTM(\n","        units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n","        return_sequences=True\n","    ), input_shape=(n_cycles, num_features)))\n","\n","    # Second Bi-LSTM layer\n","    model.add(Bidirectional(LSTM(\n","        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n","        return_sequences=False\n","    )))\n","\n","    # Dropout layer for regularization\n","    model.add(Dropout(hp.Choice('dropout', [0.0, 0.2, 0.4])))\n","\n","    # Dense layer\n","    model.add(Dense(hp.Int('dense_units', min_value=16, max_value=64, step=16), activation=\"relu\"))\n","\n","    # Output layer\n","    model.add(Dense(1))\n","\n","    # Compile model\n","    model.compile(\n","        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n","        loss=\"mse\"\n","    )\n","\n","    return model\n","\n","# Initialize tuner\n","tuner = kt.BayesianOptimization(\n","    build_bi_lstm_model,\n","    objective=\"val_loss\",\n","    max_trials=10,  # Number of different hyperparameter combinations to try\n","    directory=\"bi_lstm_tuning\",\n","    project_name=\"battery_bi_lstm_multiple_features\"\n",")\n","\n","# Run hyperparameter search\n","tuner.search(X_train_lstm, y_train_lstm, epochs=30, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Get the best model\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","print(f\"Best Hyperparameters: {best_hps.values}\")\n","\n","# Train the best model\n","best_bi_lstm_model = tuner.hypermodel.build(best_hps)\n","best_bi_lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=16, validation_data=(X_test_lstm, y_test_lstm))\n","\n","# Predict\n","y_pred_bi_lstm = best_bi_lstm_model.predict(X_test_lstm)\n","\n","# Evaluate\n","mae_bi_lstm = mean_absolute_error(y_test_lstm, y_pred_bi_lstm)\n","print(f\"Optimized Bi-LSTM MAE (multiple features): {mae_bi_lstm:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFYGl7Q-gn8F","executionInfo":{"status":"ok","timestamp":1741921908348,"user_tz":420,"elapsed":88445,"user":{"displayName":"曾曼凌","userId":"08191491040602387455"}},"outputId":"8f57fcc6-0dbc-480e-9198-2c7a561722b1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Reloading Tuner from bi_lstm_tuning/battery_bi_lstm_multiple_features/tuner0.json\n","Best Hyperparameters: {'units_1': 96, 'units_2': 32, 'dropout': 0.4, 'dense_units': 16, 'learning_rate': 0.001}\n","Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 443ms/step - loss: 0.5573 - val_loss: 0.0087\n","Epoch 2/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0769 - val_loss: 0.0314\n","Epoch 3/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0499 - val_loss: 0.0112\n","Epoch 4/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0394 - val_loss: 0.0230\n","Epoch 5/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0305 - val_loss: 0.0274\n","Epoch 6/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0344 - val_loss: 0.0252\n","Epoch 7/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0320 - val_loss: 0.0351\n","Epoch 8/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0296 - val_loss: 0.0277\n","Epoch 9/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0216 - val_loss: 0.0236\n","Epoch 10/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0272 - val_loss: 0.0397\n","Epoch 11/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 259ms/step - loss: 0.0299 - val_loss: 0.0509\n","Epoch 12/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0265 - val_loss: 0.0667\n","Epoch 13/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0280 - val_loss: 0.0705\n","Epoch 14/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0191 - val_loss: 0.0897\n","Epoch 15/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0180 - val_loss: 0.0765\n","Epoch 16/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0217 - val_loss: 0.0831\n","Epoch 17/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0211 - val_loss: 0.0742\n","Epoch 18/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0177 - val_loss: 0.0687\n","Epoch 19/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0146 - val_loss: 0.0526\n","Epoch 20/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - loss: 0.0195 - val_loss: 0.0423\n","Epoch 21/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0189 - val_loss: 0.0494\n","Epoch 22/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0156 - val_loss: 0.0395\n","Epoch 23/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0170 - val_loss: 0.0377\n","Epoch 24/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0213 - val_loss: 0.0504\n","Epoch 25/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0157 - val_loss: 0.0499\n","Epoch 26/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0132 - val_loss: 0.0454\n","Epoch 27/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0131 - val_loss: 0.0477\n","Epoch 28/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0136 - val_loss: 0.0405\n","Epoch 29/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - loss: 0.0214 - val_loss: 0.0499\n","Epoch 30/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - loss: 0.0180 - val_loss: 0.0447\n","Epoch 31/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0164 - val_loss: 0.0501\n","Epoch 32/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0119 - val_loss: 0.0503\n","Epoch 33/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0124 - val_loss: 0.0567\n","Epoch 34/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0135 - val_loss: 0.0465\n","Epoch 35/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0133 - val_loss: 0.0467\n","Epoch 36/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0104 - val_loss: 0.0457\n","Epoch 37/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0112 - val_loss: 0.0384\n","Epoch 38/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0124 - val_loss: 0.0399\n","Epoch 39/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0123 - val_loss: 0.0366\n","Epoch 40/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - loss: 0.0095 - val_loss: 0.0375\n","Epoch 41/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0091 - val_loss: 0.0350\n","Epoch 42/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0114 - val_loss: 0.0322\n","Epoch 43/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0114 - val_loss: 0.0361\n","Epoch 44/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0125 - val_loss: 0.0310\n","Epoch 45/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0081 - val_loss: 0.0315\n","Epoch 46/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0117 - val_loss: 0.0301\n","Epoch 47/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0114 - val_loss: 0.0293\n","Epoch 48/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0113 - val_loss: 0.0221\n","Epoch 49/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - loss: 0.0117 - val_loss: 0.0252\n","Epoch 50/50\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0128 - val_loss: 0.0258\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n","Optimized Bi-LSTM MAE (multiple features): 0.1430\n"]}]}]}